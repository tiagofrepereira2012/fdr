{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness in Biometrics: a figure of merit to assess biometric verification\n",
    "\n",
    "This notebook is an extension of the paper `Fairness in Biometrics: a figure of merit to assess biometric verification`.\n",
    "The goal is to give a little bit more intuition about the issues with respect to fairness in biometric verification and how the Fairness Discrepancy Rate can be usefull.\n",
    "\n",
    "## Fair example\n",
    "\n",
    "The cell below presents the fair example from section 3.1\n",
    "Play with the variables below to sense the problematic of having one decision threshold that is fair to **all demographic groups**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e365ecb00d1464a89903c355a7d7826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "#################################################\n",
    "## PLAYGROUND: PLAY WITH THE VALUES OF VARIABLES BELOW TO CHANGE THE BEHAVIOUR OF THE FAIR VERIFICATION SYSTEM\n",
    "\n",
    "# RANGE OF DECISION THRESHOLDS USED IN THE DEVELOPMENT SET\n",
    "TEN_POWER_OF_X = [0.1, 0.01, 0.001, 0.0001, 0.00001] # BASICALLY, THE FMR THRESHOLDS\n",
    "\n",
    "# NUMBER OF IDENTITIES PER DEMOGRAPHIC\n",
    "IDENTITIES_PER_DEMOGRAPHIC = 100\n",
    "\n",
    "# REPRESENTS HOW A SAMPLES ARE SAMPLED\n",
    "# EACH COLUMN REPRESENTS ONE DEMOGRAPHIC.\n",
    "# THE VALUES REPRESENTS THE AVERAGE EUCLIDEAN DISTANCE BETWEEN EACH IDENTITY\n",
    "# EACH IDENTITY IS SAMPLED IN THE CORNER OF A HYPERCUBE\n",
    "DEMOGRAPHIC_MEAN_DISTANCE = [1, 1, 1]\n",
    "# EACH COLUMN REPRESENTS ONE DEMOGRAPHIC.\n",
    "# THE VALUES REPRESENTS THE STANDARD DEVIATIONS OF THE SAMPLES SAMPLED IN THE CORNER OF A HYPERCUBE\n",
    "DEMOGRAPHIC_STD = [0.2, 0.2, 0.2]\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "import plots\n",
    "import experiments\n",
    "import scoring\n",
    "import fairness_metric\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# fetching the samples\n",
    "impostors_per_demographic_dev_fair, genuines_per_demographic_dev_fair, \\\n",
    "impostors_per_demographic_eval_fair, genuines_per_demographic_eval_fair,_ = experiments.generate_abstract_experiment(\n",
    "    DEMOGRAPHIC_DISPLACEMENTS = DEMOGRAPHIC_MEAN_DISTANCE,\n",
    "    DEMOGRAPHIC_STD = DEMOGRAPHIC_STD,    \n",
    "    FAR_THRESHOLDS=TEN_POWER_OF_X,\n",
    "    DEV_EVAL_IDENTITIES_PER_DEMOGRAPHIC=IDENTITIES_PER_DEMOGRAPHIC\n",
    ")\n",
    "\n",
    "n_demographics_fair = len(DEMOGRAPHIC_MEAN_DISTANCE)\n",
    "\n",
    "# computing TAU USING THE ZEROTH-EFFORT IMPOSTORS from the development set\n",
    "taus_fair = scoring.compute_thresholds(impostors_per_demographic_dev_fair, TEN_POWER_OF_X)\n",
    "\n",
    "# Plot Figure 1 using data from evaluation set\n",
    "plots.plot_cohort_box_plot(impostors_per_demographic_eval_fair, \n",
    "                     genuines_per_demographic_eval_fair, \n",
    "                     [f\"{i}\" for i in range(n_demographics_fair)],\n",
    "                     thresholds=taus_fair,\n",
    "                     far_thresholds=[10**(i+1) for i,_ in enumerate(TEN_POWER_OF_X)]\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfair example\n",
    "\n",
    "The cell below presents the UNfair example from section 3.1\n",
    "Play with the variables below to sense the problematic of having one decision threshold that is fair to **all demographic groups**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd773e107514f2bb4345ea155687a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################\n",
    "## PLAYGROUND: PLAY WITH THE VALUES OF VARIABLES BELOW TO CHANGE THE BEHAVIOUR OF THE FAIR VERIFICATION SYSTEM\n",
    "\n",
    "# NUMBER OF IDENTITIES PER DEMOGRAPHIC\n",
    "IDENTITIES_PER_DEMOGRAPHIC = 100\n",
    "\n",
    "# REPRESENTS HOW A SAMPLES ARE SAMPLED\n",
    "# EACH COLUMN REPRESENTS ONE DEMOGRAPHIC.\n",
    "# THE VALUES REPRESENTS THE AVERAGE EUCLIDEAN DISTANCE BETWEEN EACH IDENTITY\n",
    "# EACH IDENTITY IS SAMPLED IN THE CORNER OF A HYPERCUBE\n",
    "DEMOGRAPHIC_MEAN_DISTANCE = [0.8, 1.3, 1.5]\n",
    "# EACH COLUMN REPRESENTS ONE DEMOGRAPHIC.\n",
    "# THE VALUES REPRESENTS THE STANDARD DEVIATIONS OF THE SAMPLES SAMPLED IN THE CORNER OF A HYPERCUBE\n",
    "DEMOGRAPHIC_STD = [0.1, 0.2, 0.4]\n",
    "#################################################\n",
    "\n",
    "n_demographics_unfair = len(DEMOGRAPHIC_MEAN_DISTANCE)\n",
    "\n",
    "impostors_per_demographic_dev_unfair, genuines_per_demographic_dev_unfair, \\\n",
    "impostors_per_demographic_eval_unfair, genuines_per_demographic_eval_unfair, _ = \\\n",
    "experiments.generate_abstract_experiment(DEMOGRAPHIC_DISPLACEMENTS=DEMOGRAPHIC_MEAN_DISTANCE,\n",
    "                                        DEMOGRAPHIC_STD=DEMOGRAPHIC_STD,\n",
    "                                        DEV_EVAL_IDENTITIES_PER_DEMOGRAPHIC=IDENTITIES_PER_DEMOGRAPHIC)\n",
    "                       \n",
    "# computing TAU USING THE ZEROTH-EFFORT IMPOSTORS from the development set\n",
    "taus_unfair = scoring.compute_thresholds(impostors_per_demographic_dev_unfair, TEN_POWER_OF_X)\n",
    "\n",
    "# Plot Figure 1 using data from evaluation set\n",
    "plots.plot_cohort_box_plot(impostors_per_demographic_eval_unfair,\n",
    "                           genuines_per_demographic_eval_unfair,\n",
    "                           [f\"{i}\" for i in range(n_demographics_unfair)],\n",
    "                           thresholds=taus_unfair,\n",
    "                           far_thresholds=[10**(i+1) for i,_ in enumerate(taus_unfair)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Discrepancy Curve\n",
    "\n",
    "It computes **FDR** for the synthetic fair and unfair systems and computes the Area Under FDR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ea93af296845558e764d6726d4e21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU-FPR from fair system 0.9992738830317849\n",
      "AU-FPR from unfair system 0.660289730763997\n"
     ]
    }
   ],
   "source": [
    "import fairness_metric\n",
    "\n",
    "### FAIR\n",
    "f_tau_fair = fairness_metric.compute_fairness_biometric_verification(impostors_per_demographic_eval_fair, \n",
    "                                                                     genuines_per_demographic_eval_fair,\n",
    "                                                                     taus_fair,\n",
    "                                                                     len(taus_fair),\n",
    "                                                                     n_demographics_fair)\n",
    "\n",
    "f_tau_unfair = fairness_metric.compute_fairness_biometric_verification(impostors_per_demographic_eval_unfair,\n",
    "                                                                       genuines_per_demographic_eval_unfair,\n",
    "                                                                       taus_unfair,\n",
    "                                                                       len(taus_unfair),\n",
    "                                                                       n_demographics_unfair)\n",
    "\n",
    "fairness_metric.fairness_plot_clean([f_tau_fair,f_tau_unfair],\n",
    "                                    labels=[\"Fair Biom. System\",\"Unfair Biom. System\"],\n",
    "                                    far_thresholds=TEN_POWER_OF_X,\n",
    "                                    title=\"\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"AU-FPR from fair system {fairness_metric.fpr_auc_score(f_tau_fair, TEN_POWER_OF_X)}\")\n",
    "print(f\"AU-FPR from unfair system {fairness_metric.fpr_auc_score(f_tau_unfair, TEN_POWER_OF_X)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# The limits of fairness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
